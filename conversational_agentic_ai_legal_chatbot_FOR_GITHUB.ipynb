{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01a46f5f-f418-4494-b264-c5b28595f684",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 18:07:00.477 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-14 18:07:00.478 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-14 18:07:01.475 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\Admin\\Anaconda3\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-10-14 18:07:01.476 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-14 18:07:01.477 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-14 18:07:01.478 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-14 18:07:01.479 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-14 18:07:01.481 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-14 18:07:01.482 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-14 18:07:01.483 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-14 18:07:01.484 Session state does not function when running a script without `streamlit run`\n",
      "2025-10-14 18:07:01.485 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-14 18:07:01.486 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-14 18:07:01.488 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-14 18:07:01.489 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-14 18:07:01.491 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-14 18:07:01.492 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-14 18:07:01.493 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import openai\n",
    "import os\n",
    "\n",
    "# Set your OpenAI API key securely\n",
    "openai.api_key = 'open API key'\n",
    "\n",
    "# Initialize session state\n",
    "if \"chat_history\" not in st.session_state:\n",
    "    st.session_state.chat_history = []\n",
    "if \"context_buffer\" not in st.session_state:\n",
    "    st.session_state.context_buffer = \"\"\n",
    "if \"temp_input\" not in st.session_state:\n",
    "    st.session_state.temp_input = \"\"\n",
    "\n",
    "st.set_page_config(page_title=\"Agentic Legal Chatbot\", layout=\"centered\")\n",
    "st.title(\"⚖️ Conversational Agentic Legal Chatbot\")\n",
    "st.markdown(\"Ask any legal question related to Indian law. You can follow up with more questions — the bot remembers previous answers.\")\n",
    "\n",
    "# Input box using a temporary key\n",
    "user_input = st.text_input(\"Your message:\", value=st.session_state.temp_input, key=\"input_box\")\n",
    "\n",
    "# 🧠 Step 1: Classify the query\n",
    "def classify_query(query: str) -> str:\n",
    "    system_prompt = \"You are a legal classifier. Categorize the query into one of: 'Criminal Law', 'Civil Law', 'Constitutional Law', 'Family Law', 'Corporate Law', or 'Other'.\"\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ],\n",
    "        temperature=0.3,\n",
    "        max_tokens=50\n",
    "    )\n",
    "    return response['choices'][0]['message']['content'].strip()\n",
    "\n",
    "# 🧩 Step 2: Plan reasoning steps\n",
    "def plan_steps(category: str, query: str) -> str:\n",
    "    planner_prompt = f\"\"\"\n",
    "You are a legal planning agent. Based on the category '{category}', break down the user's query into logical steps to answer it thoroughly. Be specific and methodical.\n",
    "Query: {query}\n",
    "\"\"\"\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a legal planning agent.\"},\n",
    "            {\"role\": \"user\", \"content\": planner_prompt}\n",
    "        ],\n",
    "        temperature=0.4,\n",
    "        max_tokens=50\n",
    "    )\n",
    "    return response['choices'][0]['message']['content'].strip()\n",
    "\n",
    "# 🔍 Step 3: Simulate tool use\n",
    "def simulate_tool_use(category: str, query: str) -> str:\n",
    "    tool_prompt = f\"\"\"\n",
    "You are a legal assistant with access to Indian legal databases. Simulate what kind of external sources or tools you would use to answer this query, such as case law, statutes, or government portals.\n",
    "Category: {category}\n",
    "Query: {query}\n",
    "\"\"\"\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a legal assistant simulating tool use.\"},\n",
    "            {\"role\": \"user\", \"content\": tool_prompt}\n",
    "        ],\n",
    "        temperature=0.5,\n",
    "        max_tokens=50\n",
    "    )\n",
    "    return response['choices'][0]['message']['content'].strip()\n",
    "\n",
    "# 🧾 Step 4: Generate final response with context\n",
    "def generate_response(query: str, category: str, steps: str, tools: str, context: str) -> str:\n",
    "    full_prompt = f\"\"\"\n",
    "You are a legal expert in Indian law. Engage in a helpful, conversational tone.\n",
    "\n",
    "Here is relevant context from previous conversation:\n",
    "{context}\n",
    "\n",
    "Current query: {query}\n",
    "\n",
    "Category: {category}\n",
    "Reasoning Steps: {steps}\n",
    "Simulated Tool Use: {tools}\n",
    "\n",
    "Now, provide a clear, accurate, and legally grounded response to the user's query.\n",
    "\"\"\"\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a legal expert in Indian law.\"},\n",
    "            {\"role\": \"user\", \"content\": full_prompt}\n",
    "        ],\n",
    "        temperature=0.5,\n",
    "        max_tokens=50\n",
    "    )\n",
    "    return response['choices'][0]['message']['content'].strip()\n",
    "\n",
    "# 🔘 Trigger agentic flow\n",
    "if st.button(\"Send\"):\n",
    "    if user_input.strip():\n",
    "        # Append all previous assistant answers to context buffer\n",
    "        for msg in st.session_state.chat_history:\n",
    "            if msg[\"role\"] == \"assistant\":\n",
    "                st.session_state.context_buffer += f\"\\nPrevious answer: {msg['content']}\"\n",
    "\n",
    "        with st.spinner(\"Classifying your query...\"):\n",
    "            category = classify_query(user_input)\n",
    "\n",
    "        with st.spinner(f\"Planning steps for {category}...\"):\n",
    "            steps = plan_steps(category, user_input)\n",
    "\n",
    "        with st.spinner(\"Simulating tool use...\"):\n",
    "            tools = simulate_tool_use(category, user_input)\n",
    "\n",
    "        with st.spinner(\"Generating legal response...\"):\n",
    "            response = generate_response(user_input, category, steps, tools, st.session_state.context_buffer)\n",
    "\n",
    "        # Update chat history\n",
    "        st.session_state.chat_history.append({\"role\": \"user\", \"content\": user_input})\n",
    "        st.session_state.chat_history.append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "        # Clear input for next turn\n",
    "        st.session_state.temp_input = \"\"\n",
    "\n",
    "# Display conversation\n",
    "if st.session_state.chat_history:\n",
    "    st.markdown(\"### 💬 Conversation\")\n",
    "    for msg in st.session_state.chat_history:\n",
    "        if msg[\"role\"] == \"user\":\n",
    "            st.markdown(f\"**You:** {msg['content']}\")\n",
    "        else:\n",
    "            st.markdown(f\"**Bot:** {msg['content']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc86870-bff7-451f-b8dd-b8cb053ffd64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
